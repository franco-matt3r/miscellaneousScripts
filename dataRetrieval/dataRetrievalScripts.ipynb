{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook shares template code to ease data access from AWS\n",
    "this code was written as example by copying/pasting and by memory, so you must update the value names(it won't necessarily run as is because the filename may have been deleted, etc). Let me know if you experience any trouble."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cell 1: Using raw CANServer data\n",
    "\n",
    "1) Download the teslax app on ios to understand the data codes: https://teslax.app/\n",
    "\n",
    "2) Convert the binary log files into readable log file: git clone https://github.com/joshwardell/CANserver/tree/main, navigate to tools/python3_module/, then in terminal type python3 convertbinarytoasc.py -i input.log -o output.txt, where input.log is the log file to convert and output.txt is the desired name of the output file\n",
    "\n",
    "3) Convert the binary log files to csv files containing only the data matt3r needs for now: git clone https://github.com/matt3r-ai/canbus-analyzer, then in terminal type python3 can_reader.py input.log, where input.log is the log file to convert. the input will land in the data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Using data from S3 buckets\n",
    "\n",
    "import boto3\n",
    "import json\n",
    "import logging\n",
    "\n",
    "CANSERVER_RAW_BUCKET: \"matt3r-canserver-raw-us-west-2\"\n",
    "CANSERVER_PARSED_BUCKET: \"matt3r-canserver-us-west-2\"\n",
    "CANSERVER_EVENT_BUCKET: \"matt3r-canserver-event-us-west-2\"\n",
    "IMU_BUCKET: \"matt3r-imu-us-west-2\"\n",
    "TESLA_API_BUCKET: \"matt3r-raw-vehicle-data-bucket-parquet-dev-us-west-2\"\n",
    "VIDEO_BUCKET: \"matt3r-driving-footage-us-west-2\"\n",
    "AUDIO_BUCKET: \"matt3r-audio-recording-us-west-2\"\n",
    "MDP_API_RESULT_BUCKET: \"matt3r-mdp-api-backend-results-us-west-2\"\n",
    "\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "# Listing all files in a bucket given a prefix\n",
    "response = s3_client.list_objects(Bucket=CANSERVER_PARSED_BUCKET, Prefix=\"test-suite/\")\n",
    "keys = [item['Key'] for item in response['Contents']]\n",
    "\n",
    "# Getting a single json file from a bucket\n",
    "response = s3_client.get_object(Bucket=CANSERVER_EVENT_BUCKET, Key=\"test-suite/key123/2023-01-10_18_00_00.json\")\n",
    "result = json.loads(response[\"Body\"].read().decode())\n",
    "\n",
    "# uploading any file type to a bucket\n",
    "response = s3_client.put_object(Bucket=CANSERVER_PARSED_BUCKET, Key=\"test-suite/key123/2023-01-10_18_00_00.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: using parquet files\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "# getting parquet file from s3\n",
    "response = s3_client.get_object(Bucket=CANSERVER_PARSED_BUCKET, Key=\"test-suite/key123/2023-01-10_18_00_00.parquet\")\n",
    "buffer = BytesIO(response['Body'].read())\n",
    "parquet_df = pd.read_parquet(buffer, engine='pyarrow')\n",
    "\n",
    "# OR for myltiple files, you can use pyarrow's ParquetDataset\n",
    "prefixes = [\"test-suite/key123/2023-01-10_18_00_00.parquet, test-suite/key123/2023-01-10_19_00_00.parquet\"]\n",
    "start_timestamp = 1681490347.0\n",
    "end_timestamp = 1681491900.0\n",
    "filter_expr = [('timestamp', '>', start_timestamp),('timestamp', '<', end_timestamp)]\n",
    "bucket_path = \"s3://\" + TESLA_API_BUCKET + \"/\"\n",
    "columns = [\"timestamp\", \"bf_acc\"]\n",
    "table = pq.ParquetDataset(prefixes, filesystem=bucket_path, filters=filter_expr).read(columns)\n",
    "df = table.to_pandas()\n",
    "\n",
    "# getting parquet file from local\n",
    "df = pd.read_parquet(\"local/path/file.parquet\")\n",
    "\n",
    "# Sometimes i find VSCode has difficulty with displaying parquet files, so you can convert it to csv\n",
    "df.to_csv('local/path/file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Using AWS AppSync to query organisational data\n",
    "\n",
    "from gql import gql\n",
    "from gql.client import Client\n",
    "from gql.transport.requests import RequestsHTTPTransport\n",
    "from requests_aws4auth import AWS4Auth\n",
    "from boto3 import Session as AWSSession\n",
    "APPSYNC_ENDPOINT = \"https://3ybqvhla55ff7ihuasuzk6rbwy.appsync-api.us-west-2.amazonaws.com/graphql\"\n",
    "\n",
    "\n",
    "def parse_region_from_url(url):\n",
    "    try:\n",
    "        \"\"\"Parses the region from the appsync url, so we call the correct region\n",
    "        regardless of the session or the argument. \n",
    "        Example URL: https://xxxxxxx.appsync-api.us-east-2.amazonaws.com/graphql\"\"\"\n",
    "        split = url.split('.')\n",
    "        if 2 < len(split):\n",
    "            return split[2]\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        logging.log(\"parse_region_from_url() failed with error:\", e)\n",
    "    \n",
    "def app_sync_client(query, params):\n",
    "    \"\"\"AppSync client to execute queries\"\"\"\n",
    "    try: \n",
    "        headers = {\n",
    "            'Accept': 'application/json',\n",
    "            'Content-Type': 'application/json',\n",
    "        }\n",
    "\n",
    "        aws = AWSSession()\n",
    "        credentials = aws.get_credentials()\n",
    "        region = parse_region_from_url(APPSYNC_ENDPOINT)\n",
    "        auth = AWS4Auth(refreshable_credentials=credentials, region=region, service='appsync')\n",
    "        transport = RequestsHTTPTransport(url=APPSYNC_ENDPOINT, headers=headers, auth=auth)\n",
    "        client = Client(transport=transport, fetch_schema_from_transport=True)\n",
    "        response = client.execute(gql(query), variable_values=json.dumps(params))\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        logging.log(\"app_sync_client() failed with error:\", e)\n",
    "        \n",
    "query = \"\"\" \n",
    "    query MyQuery ($id: ID!) {\n",
    "        TeslaVehiclebyKeyId(key_id:$id) {\n",
    "            items {\n",
    "                    id\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    \"\"\"\n",
    "params = {\"id\": \"key123\"}\n",
    "response = app_sync_client(query, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Using postgres tables \n",
    "\n",
    "from sqlalchemy import create_engine, Column, Integer, Date, VARCHAR, UniqueConstraint, and_\n",
    "from sqlalchemy.dialects.postgresql import JSONB\n",
    "from sqlalchemy.orm import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy.orm import Session\n",
    "import datetime from datetime\n",
    "CATALOG_USERNAME: \"Get it from 1Password\"\n",
    "CATALOG_PASSWORD: \"Get it from 1Password\"\n",
    "CATALOG_PORT: 5432\n",
    "CATALOG_DATABASE: postgres\n",
    "CATALOG_ENDPOINT: \"data-catalog.cbbarg1ot9rc.us-west-2.rds.amazonaws.com\"\n",
    "DB_URI = f'postgresql://{CATALOG_USERNAME}:{CATALOG_PASSWORD}@{CATALOG_ENDPOINT}:{CATALOG_PORT}/{CATALOG_DATABASE}'\n",
    "\n",
    "engine = create_engine(DB_URI)\n",
    "Base = declarative_base()\n",
    "class TeslaDashcam(Base):\n",
    "    __tablename__ = 'tesla_dashcam'\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    k3y_id = Column(VARCHAR(20), nullable=False)\n",
    "    date = Column(Date, nullable=False)\n",
    "    updated_time = Column(Integer)\n",
    "    created_time = Column(Integer)\n",
    "    meta_data = Column(JSONB)\n",
    "    __table_args__ = (\n",
    "        UniqueConstraint('k3y_id', 'date', name='k3y_with_date'),\n",
    "        {'extend_existing': True}\n",
    "    )\n",
    "\n",
    "class TeslaApi(Base):\n",
    "    __tablename__ = 'tesla_api'\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    vehicle_id = Column(VARCHAR(20), nullable=False)\n",
    "    date = Column(Date, nullable=False)\n",
    "    updated_time = Column(Integer)\n",
    "    created_time = Column(Integer)\n",
    "    meta_data = Column(JSONB)\n",
    "    __table_args__ = (\n",
    "        UniqueConstraint('vehicle_id', 'date', name='vehicle_with_date'),\n",
    "        {'extend_existing': True}\n",
    "    )\n",
    "\n",
    "class CanServer(Base):\n",
    "    __tablename__ = 'can_server'\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    k3y_id = Column(VARCHAR(20), nullable=False)\n",
    "    org_id = Column(VARCHAR(20), nullable=False)\n",
    "    date = Column(Date, nullable=False)\n",
    "    parsed_field_version = Column(Integer, nullable=False)\n",
    "    last_updated_time = Column(Integer)\n",
    "    created_time = Column(Integer)\n",
    "    meta_data = Column(JSONB)\n",
    "    __table_args__ = (\n",
    "        UniqueConstraint('k3y_id', 'date', name='k3y_to_date'),\n",
    "        {'extend_existing': True}\n",
    "    )\n",
    "\n",
    "date = datetime.utcfromtimestamp(given_timestamp).date()\n",
    "session = Session(bind=engine)\n",
    "records = session.query(TeslaDashcam).filter(TeslaDashcam.k3y_id == \"key123\", TeslaDashcam.date == date).all()\n",
    "for r in records:\n",
    "    print(r.id)\n",
    "    print(r.meta_data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Using the new MDP API to get data (Beta)\n",
    "# documentation: https://docs.google.com/document/d/1yW-E0rnT7pEpWQH56uR-9uGuVCudeoD4CJa9KoRSaE0/edit#heading=h.ky9lzpltnbg1\n",
    "import requests\n",
    "\n",
    "API_URL = \"https://8ti0px0ee3.execute-api.us-west-2.amazonaws.com/dev\"\n",
    "ENDPOINT = \"/mdp?\"\n",
    "\n",
    "params = {\n",
    "        \"data_source\": \"video\",\n",
    "        \"organization_id\": \"hamid\",\n",
    "        \"k3y_id\": \"k3y-9ed5b50e\",\n",
    "        \"time_interval\": \"1676336541.123$1676336602.456\",\n",
    "        \"field\": \"front\"\n",
    "        }\n",
    "response = requests.get(API_URL + ENDPOINT, params=params, timeout=30)\n",
    "parsed_response = json.loads(response.text)\n",
    "status_code = parsed_response['statusCode']\n",
    "body = parsed_response['body']\n",
    "\n",
    "if status_code == 200 or status_code == 206:\n",
    "    response = s3_client.get_object(Bucket=MDP_API_RESULT_BUCKET, Key=body)\n",
    "    result = json.loads(response[\"Body\"].read().decode())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
